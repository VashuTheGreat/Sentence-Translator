{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "cded269e-bb87-4958-bf82-413080506404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "dffe4caf-ea0a-42a8-9841-9846dbe11776",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('fra.txt', sep='\\t', header=None, names=['English', 'French'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "bb1d081b-2167-4d04-b293-192ee77b59f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[:8000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "30c182a4-dfcf-4520-a5ca-c8a13fd05d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>French</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Va !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Cours !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Courez !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wow!</td>\n",
       "      <td>Ça alors !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fire!</td>\n",
       "      <td>Au feu !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>Look for clues.</td>\n",
       "      <td>Cherchez des indices.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>Lunch is ready.</td>\n",
       "      <td>Le repas est prêt.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>Make an effort.</td>\n",
       "      <td>Fais un effort.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>Make your move.</td>\n",
       "      <td>Fais ton mouvement.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>Make your move.</td>\n",
       "      <td>Faites votre mouvement.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              English                   French\n",
       "0                 Go.                     Va !\n",
       "1                Run!                  Cours !\n",
       "2                Run!                 Courez !\n",
       "3                Wow!               Ça alors !\n",
       "4               Fire!                 Au feu !\n",
       "...               ...                      ...\n",
       "7995  Look for clues.    Cherchez des indices.\n",
       "7996  Lunch is ready.       Le repas est prêt.\n",
       "7997  Make an effort.          Fais un effort.\n",
       "7998  Make your move.      Fais ton mouvement.\n",
       "7999  Make your move.  Faites votre mouvement.\n",
       "\n",
       "[8000 rows x 2 columns]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "005c373e-0a1b-42fe-87cf-490ac14701b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prep_text(s): \n",
    "    return \" \".join(s.strip().lower().split())\n",
    "\n",
    "    \n",
    "data[\"English\"] = data[\"English\"].apply(prep_text)\n",
    "data[\"French\"]  = data[\"French\"].apply(lambda s: f\"start_ {prep_text(s)} _end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "618b601d-ac74-4eba-86f1-852cfb9968e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>French</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go.</td>\n",
       "      <td>start_ va ! _end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>run!</td>\n",
       "      <td>start_ cours ! _end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run!</td>\n",
       "      <td>start_ courez ! _end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wow!</td>\n",
       "      <td>start_ ça alors ! _end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fire!</td>\n",
       "      <td>start_ au feu ! _end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>look for clues.</td>\n",
       "      <td>start_ cherchez des indices. _end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>lunch is ready.</td>\n",
       "      <td>start_ le repas est prêt. _end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>make an effort.</td>\n",
       "      <td>start_ fais un effort. _end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>make your move.</td>\n",
       "      <td>start_ fais ton mouvement. _end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>make your move.</td>\n",
       "      <td>start_ faites votre mouvement. _end</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              English                               French\n",
       "0                 go.                     start_ va ! _end\n",
       "1                run!                  start_ cours ! _end\n",
       "2                run!                 start_ courez ! _end\n",
       "3                wow!               start_ ça alors ! _end\n",
       "4               fire!                 start_ au feu ! _end\n",
       "...               ...                                  ...\n",
       "7995  look for clues.    start_ cherchez des indices. _end\n",
       "7996  lunch is ready.       start_ le repas est prêt. _end\n",
       "7997  make an effort.          start_ fais un effort. _end\n",
       "7998  make your move.      start_ fais ton mouvement. _end\n",
       "7999  make your move.  start_ faites votre mouvement. _end\n",
       "\n",
       "[8000 rows x 2 columns]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "10fd96ec-b32f-46d5-ad34-b6f6b97df820",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "filters = '\"!#$%&()*+,-./:;=?@[\\\\]^`{|}~\\t\\n' \n",
    "tokenizer_e = Tokenizer(filters=filters, lower=True, oov_token=None)\n",
    "tokenizer_f = Tokenizer(filters=filters, lower=True, oov_token=None)\n",
    "\n",
    "\n",
    "# creating Two Tokenizers\n",
    "tokenizer_e.fit_on_texts(data[\"English\"])\n",
    "tokenizer_f.fit_on_texts(data[\"French\"])\n",
    "\n",
    "\n",
    "# creating source and target vectors \n",
    "src_seq = tokenizer_e.texts_to_sequences(data[\"English\"])\n",
    "tgt_seq = tokenizer_f.texts_to_sequences(data[\"French\"])\n",
    "\n",
    "# storing the max length of the sequences\n",
    "max_len_src = max(len(s) for s in src_seq)\n",
    "max_len_tgt = max(len(s) for s in tgt_seq)\n",
    "\n",
    "\n",
    "# applying post padding to it\n",
    "src_seq = pad_sequences(src_seq, maxlen=max_len_src, padding='post')\n",
    "tgt_seq = pad_sequences(tgt_seq, maxlen=max_len_tgt, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "3df3f816-0271-4319-9bf3-76c9d254eeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tgt_input  = tgt_seq[:, :-1]            # encoder input _end ko hate hue up to last -1\n",
    "tgt_output = tgt_seq[:, 1:]             # start_ ko hatate hue upto _end\n",
    "\n",
    "vocab_src = len(tokenizer_e.word_index) + 1 # kyoki 1 se start hota h isiliye + 1 numbers of vocab size\n",
    "vocab_tgt = len(tokenizer_f.word_index) + 1 # kyoki 1 se start hota h isiliye + 1 numbers of vocab size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "c05e26e7-4eb1-4abf-bdf2-d1ba0a3749cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "\n",
    "\n",
    "latent_dim = 256 # lstm nodes \n",
    "\n",
    "# encoder\n",
    "enc_inputs = Input(shape=(max_len_src,))\n",
    "enc_emb = Embedding(vocab_src, 128, mask_zero=True)(enc_inputs)\n",
    "_, state_h, state_c = LSTM(latent_dim, return_state=True)(enc_emb)\n",
    "\n",
    "\n",
    "enc_states = [state_h, state_c] # context vector\n",
    "\n",
    "\n",
    "# decoder\n",
    "\n",
    "dec_inputs = Input(shape=(max_len_tgt-1,)) # kyoki ek kam de rahe h na ham isiliye -1\n",
    "dec_emb = Embedding(vocab_tgt, 128, mask_zero=True)(dec_inputs)\n",
    "dec_outputs = LSTM(latent_dim, return_sequences=True, return_state=False)(dec_emb, initial_state=enc_states)\n",
    "\n",
    "\n",
    "dec_logits = Dense(vocab_tgt, activation='softmax')(dec_outputs) # har output par ek probability return hogi har vocab ke liye \n",
    "\n",
    "# creating model\n",
    "\n",
    "model = Model([enc_inputs, dec_inputs], dec_logits)\n",
    "\n",
    "# compiling it it is mandatory to use sparse_categorical_crossentropy as jo next word h wo categorical h regration nahi \n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "4001b61d-a715-4f40-acdd-6bdab78d742b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 186ms/step - accuracy: 0.3327 - loss: 4.8245\n",
      "Epoch 2/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 187ms/step - accuracy: 0.2175 - loss: 3.5755\n",
      "Epoch 3/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 188ms/step - accuracy: 0.2327 - loss: 3.2351\n",
      "Epoch 4/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 185ms/step - accuracy: 0.2551 - loss: 2.9357\n",
      "Epoch 5/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 186ms/step - accuracy: 0.2688 - loss: 2.6749\n",
      "Epoch 6/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 186ms/step - accuracy: 0.2796 - loss: 2.4570\n",
      "Epoch 7/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 189ms/step - accuracy: 0.2898 - loss: 2.2602\n",
      "Epoch 8/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 188ms/step - accuracy: 0.2987 - loss: 2.0840\n",
      "Epoch 9/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 188ms/step - accuracy: 0.3069 - loss: 1.9182\n",
      "Epoch 10/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 188ms/step - accuracy: 0.3145 - loss: 1.7663\n",
      "Epoch 11/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 184ms/step - accuracy: 0.3221 - loss: 1.6262\n",
      "Epoch 12/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 185ms/step - accuracy: 0.3296 - loss: 1.4986\n",
      "Epoch 13/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 194ms/step - accuracy: 0.3358 - loss: 1.3802\n",
      "Epoch 14/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 189ms/step - accuracy: 0.3441 - loss: 1.2707\n",
      "Epoch 15/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 184ms/step - accuracy: 0.3509 - loss: 1.1714\n",
      "Epoch 16/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 190ms/step - accuracy: 0.3586 - loss: 1.0776\n",
      "Epoch 17/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 192ms/step - accuracy: 0.3669 - loss: 0.9905\n",
      "Epoch 18/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 190ms/step - accuracy: 0.3738 - loss: 0.9154\n",
      "Epoch 19/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 192ms/step - accuracy: 0.3800 - loss: 0.8424\n",
      "Epoch 20/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 191ms/step - accuracy: 0.3867 - loss: 0.7763\n",
      "Epoch 21/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 186ms/step - accuracy: 0.3922 - loss: 0.7187\n",
      "Epoch 22/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 191ms/step - accuracy: 0.3973 - loss: 0.6663\n",
      "Epoch 23/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 192ms/step - accuracy: 0.4017 - loss: 0.6175\n",
      "Epoch 24/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 192ms/step - accuracy: 0.4059 - loss: 0.5748\n",
      "Epoch 25/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 193ms/step - accuracy: 0.4098 - loss: 0.5365\n",
      "Epoch 26/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 187ms/step - accuracy: 0.4128 - loss: 0.5005\n",
      "Epoch 27/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 189ms/step - accuracy: 0.4158 - loss: 0.4701\n",
      "Epoch 28/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 192ms/step - accuracy: 0.4189 - loss: 0.4418\n",
      "Epoch 29/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 191ms/step - accuracy: 0.4203 - loss: 0.4174\n",
      "Epoch 30/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 189ms/step - accuracy: 0.4218 - loss: 0.3959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x28dc17822c0>"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# targets must be (batch, timesteps, 1) for sparse loss\n",
    "y_sparse = np.expand_dims(tgt_output, -1)\n",
    "\n",
    "\n",
    "# training the model\n",
    "model.fit([src_seq, tgt_input], y_sparse, batch_size=64, epochs=30, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aa8511-5af1-454a-b214-9d7928670743",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index2word_f = tokenizer_f.index_word\n",
    "word2index_f = tokenizer_f.word_index\n",
    "START_ID = word2index_f.get(\"start_\") # index of start_\n",
    "END_ID   = word2index_f.get(\"_end\") # index of _end\n",
    "\n",
    "def translate(model, en_text, max_len=50):\n",
    "    en_text = prep_text(en_text)\n",
    "    x1 = tokenizer_e.texts_to_sequences([en_text])\n",
    "    x1 = pad_sequences(x1, maxlen=max_len_src, padding='post')\n",
    "    dec = [START_ID]\n",
    "    for _ in range(min(max_len, max_len_tgt-1)):\n",
    "        x2 = pad_sequences([dec], maxlen=max_len_tgt-1, padding='post')\n",
    "        p  = model.predict([x1, x2], verbose=0)\n",
    "        next_id = int(np.argmax(p[0, len(dec)-1, :]))\n",
    "        if next_id == 0: break\n",
    "        if next_id == END_ID: break\n",
    "        dec.append(next_id)\n",
    "    words = [index2word_f.get(i, \"\") for i in dec[1:]]\n",
    "    return \" \".join([w for w in words if w])\n",
    "\n",
    "\n",
    "\n",
    "# def next_word(model, en_text, fr_prefix=\"start_\"):\n",
    "#     en_text = prep_text(en_text)\n",
    "#     x1 = tokenizer_e.texts_to_sequences([en_text])\n",
    "#     x1 = pad_sequences(x1, maxlen=max_len_src, padding='post')\n",
    "#     x2 = tokenizer_f.texts_to_sequences([prep_text(fr_prefix)])\n",
    "#     x2 = pad_sequences(x2, maxlen=max_len_tgt-1, padding='post')\n",
    "#     p  = model.predict([x1, x2], verbose=0)\n",
    "#     wid = int(np.argmax(p[0, len(x2[0].nonzero()[0]) - 1, :]))\n",
    "#     return index2word_f.get(wid, \"<unk>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "552fd36f-9668-4a74-892c-4f52afc91ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "je suis de tokyo\n"
     ]
    }
   ],
   "source": [
    "t='I am boy'\n",
    "\n",
    "pred=translate(model, t)\n",
    "print(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "c0a6e6c5-da49-482f-9ffe-7c1133640803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('french.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "8fa6c93c-adc6-4fb0-8305-92de32d8fbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "2b69c223-b952-42ad-9c90-8bd54a016857",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('french_tokenizer.pkl','wb') as f:\n",
    "    pickle.dump(tokenizer_f,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "74da6fb4-5915-4eef-8cd2-ca9af33f92c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('french_tokenizer_e.pkl','wb') as f:\n",
    "    pickle.dump(tokenizer_e,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "81d99cfe-d6de-4338-8d86-da7bc823c54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('french_max_len_src.pkl','wb') as f:\n",
    "    pickle.dump(max_len_src,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "17082718-4245-48e3-868a-5668dbec0d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('french_max_len_tgt.pkl','wb') as f:\n",
    "    pickle.dump(max_len_tgt,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ffee1b-044d-4384-b134-d18fa9f5465e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
